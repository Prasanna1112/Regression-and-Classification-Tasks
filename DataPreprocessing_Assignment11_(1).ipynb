{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPreprocessing_Assignment11 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjqX9hqbb-6"
      },
      "source": [
        "# Data.csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AketbKR7cAaF"
      },
      "source": [
        "**Step 1: Importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ApieS21bdbN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq1_kSwHcH4n"
      },
      "source": [
        "**Step 2: Importing dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HefV9KfcbdoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11d3eb2-ddb2-4f53-9a0b-a1aa6c9b0016"
      },
      "source": [
        "data = pd.read_csv('Data.csv')\n",
        "X = data.iloc[ : , :-1].values\n",
        "Y = data.iloc[ : , 3].values\n",
        "X\n",
        "# Y"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, nan],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', nan, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YLHdZ8sdkWT",
        "outputId": "38332bb5-29ea-4f4f-cb6d-ac691fd9b916"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of    Country   Age   Salary Purchased\n",
              "0   France  44.0  72000.0        No\n",
              "1    Spain  27.0  48000.0       Yes\n",
              "2  Germany  30.0  54000.0        No\n",
              "3    Spain  38.0  61000.0        No\n",
              "4  Germany  40.0      NaN       Yes\n",
              "5   France  35.0  58000.0       Yes\n",
              "6    Spain   NaN  52000.0        No\n",
              "7   France  48.0  79000.0       Yes\n",
              "8  Germany  50.0  83000.0        No\n",
              "9   France  37.0  67000.0       Yes>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxaiAQCQcX7Z"
      },
      "source": [
        "**Step 3: Handling the missing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veMJJywXbdr-"
      },
      "source": [
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values = np.nan, strategy = \"median\")\n",
        "imputer = imputer.fit(X[ : , 1:3])\n",
        "X[ : , 1:3] = imputer.transform(X[ : , 1:3])\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObOeZMD-QBsG",
        "outputId": "bcf047ec-bc09-4afc-f62d-914141229f32"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['France', 44.0, 72000.0],\n",
              "       ['Spain', 27.0, 48000.0],\n",
              "       ['Germany', 30.0, 54000.0],\n",
              "       ['Spain', 38.0, 61000.0],\n",
              "       ['Germany', 40.0, 61000.0],\n",
              "       ['France', 35.0, 58000.0],\n",
              "       ['Spain', 38.0, 52000.0],\n",
              "       ['France', 48.0, 79000.0],\n",
              "       ['Germany', 50.0, 83000.0],\n",
              "       ['France', 37.0, 67000.0]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBdj7QVmciFh"
      },
      "source": [
        "**Step 4: Encoding categorical data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbgm4YJBbdwG"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "ohencoder = OneHotEncoder(sparse=False, categorical_features = [0])\n",
        "lblencoder = LabelEncoder()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFSk6n3XcpIs"
      },
      "source": [
        "**Step 5: Creating a dummy variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ETxfCgZbd0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee938019-7029-46f3-93db-d453bdf689dd"
      },
      "source": [
        "X[ : , 0] = lblencoder.fit_transform(X[ : , 0])\n",
        "\n",
        "X = ohencoder.fit_transform(X)\n",
        "Y =  lblencoder.fit_transform(Y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 1., 1., 0., 1., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSSKm1p4c2md"
      },
      "source": [
        "**Step 6: Splitting the datasets into training sets and Test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw21hHAqbd4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4599c0d0-dcf6-4066-fcec-d30e57827bc7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X , Y, test_size = 0.2, random_state = 0)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA8VCdb5c9Dh"
      },
      "source": [
        "**Step 7: Feature Scaling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhV2lO1Gbd9l"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRwvGcTdbeCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f01d608-945a-46c0-8c15-a35be8d0466b"
      },
      "source": [
        "stdsc = StandardScaler()\n",
        "\n",
        "X_train = stdsc.fit_transform(X_train)\n",
        "X_test = stdsc.fit_transform(X_test)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.,  1.,  1., ...,  0.,  0.,  0.],\n",
              "       [ 1., -1., -1., ...,  0.,  0.,  0.],\n",
              "       [-1.,  1.,  1., ...,  0.,  0.,  0.],\n",
              "       ...,\n",
              "       [-1.,  1.,  1., ...,  0.,  0.,  0.],\n",
              "       [ 1., -1., -1., ...,  0.,  0.,  0.],\n",
              "       [ 1., -1., -1., ...,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}